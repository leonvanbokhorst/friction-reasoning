# Model Configuration
model_config:
  base_model: "unsloth/DeepSeek-R1-Distill-Qwen-14B-unsloth-bnb-4bit"
  trust_remote_code: true
  use_flash_attention_2: true  # Added from old config
  torch_dtype: "bfloat16"
  device_map: "auto"
  model_max_length: 4096  # Restored to original value

# LoRA Configuration
lora_config:
  r: 16  # Restored to original value
  lora_alpha: 32  # Restored to original value
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  bias: "none"
  task_type: "CAUSAL_LM"
  lora_dropout: 0.0  # Increased from 0.0 to help with regularization
  inference_mode: false

# Dataset Configuration
dataset_config:
  dataset_name: "leonvanbokhorst/friction-overthinking-v2"
  shuffle_seed: 42  # Added explicit shuffle seed
  columns:
    question: "question"
    agent_responses: "agent_responses"
    final_answer: "final_answer"
  format_template: | 
    <|im_start|>system
    You are a human-like AI assistant.
    <|im_end|>
    <|im_start|>user
    {question}
    <|im_end|>
    <|im_start|>assistant
    <think>
    {thought_stream}
    </think>
    {final_answer}
    <|im_end|>
# Training Configuration
training_config:
  learning_rate: 2e-4
  num_train_epochs: 5  # Reduced from 5 to prevent overfitting
  per_device_train_batch_size: 2  # Restored to original value
  gradient_accumulation_steps: 4  # Restored to original value
  warmup_ratio: 0.1
  logging_steps: 10
  evaluation_strategy: "steps"
  eval_steps: 50  # More frequent evaluation to catch overfitting earlier
  save_strategy: "steps"
  save_steps: 50  # More frequent saving to capture best model
  save_total_limit: 5  # Increased to keep more checkpoints
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  early_stopping_patience: 3  # Reduced patience to stop earlier when overfitting
  early_stopping_threshold: 0.005  # More sensitive threshold
  gradient_checkpointing: true
  optim: "adamw_8bit"
  fp16: false
  bf16: true
  report_to: ["wandb"]
  weight_decay: 0.01  # Added L2 regularization
  max_grad_norm: 0.5  # Added gradient clipping

# Output Configuration
output_config:
  output_dir: "models/friction_reasoning"  # Changed to match our project structure
  logging_dir: "logs/friction_reasoning"  # Changed to match our project structure 